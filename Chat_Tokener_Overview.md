# ChatTokener: Your Digital Brain for AI Conversations

ChatTokener is like having a **personal assistant that never forgets** your conversations with AI.

Imagine: you're developing with Claude, solve a complex problem after hours of discussion, then close the chat and... *poof*, everything disappears. ChatTokener was born to say "enough!" to this frustration.

## ğŸ” **Intelligent Conversation Visualization**

ChatTokener transforms your chaotic conversations into a structured navigation experience:

- **ğŸ“‹ Turn-by-Turn Visualization**: Each chat is presented as an ordered sequence of questions-answers, making it easy to follow the thread of discourse
- **ğŸ¯ Granular Summaries**: Every single turn receives its micro-summary/title, allowing you to immediately understand what it's about without having to read everything
- **ğŸ“– General Summary**: At the beginning of each summary there's a complete overview of the conversation, giving you the general context before diving into details
- **ğŸ“‘ Unified Document**: There's even a magic function that collects all the general summaries from all your chats and instantly creates a single overview document

## ğŸ“Š **The Origins: Observability and Metrics**

Actually ChatTokener (hence the name) was initially born from a very practical need: having **observability on chat dimensions**. Knowing how many tokens, words and characters the conversations were large to make strategic decisions on context windows during chats with the assistant.

This soul has remained and indeed ChatTokener produces **detailed statistics** on:
- **ğŸ“ˆ Per-chat metrics**: tokens, words, characters, equivalent A4 pages
- **ğŸ“Š Aggregate statistics**: analysis of all chats together
- **ğŸ¯ Summary metrics**: compression achieved and efficiency
- **ğŸ’ Compression results**: with the default prompt, compression between original chat and summary of **50-70%** is achieved

This means that if you want to use a conversation as a starting point for a subsequent conversation, you can provide the **turn-by-turn summary** which represents a **significant saving on the context window** of the subsequent conversation while absolutely not losing detail!

## ğŸ•¸ï¸ **Integrated RAG System with Knowledge Graphs**

ChatTokener doesn't stop at summarization: it integrates a powerful RAG system that preserves knowledge in **two parallel graph-based systems**:

- **ğŸ”— LightRAG**: Advanced RAG system for semantic retrieval
- **ğŸ•¸ï¸ Graphiti**: Knowledge graph for conceptual connections with Chronological Awareness
- **ğŸ—„ï¸ Neo4j Backend**: Both systems use Neo4j as graph database

When you preserve summaries in these graph databases for subsequent consultation via MCP, you get a **much more efficient** but **not detail-lacking** system thanks to the turn-by-turn nature of the summaries.

## ğŸ§  **The Result: Permanent Technical Memory**

ChatTokener transforms the chaos of AI chats into your **permanent technical memory**. Every conversation becomes a permanent asset that:

- ğŸ” **Is easily found** through semantic search
- ğŸ”— **Intelligently connects** with other related conversations  
- ğŸ’¾ **Is efficiently preserved** thanks to intelligent compression
- ğŸ“ˆ **Improves over time** building an increasingly rich knowledge network

So when you need that OAuth solution from 3 months ago, or that brilliant debugging pattern, you no longer have to think "damn, where did I solve that?" - just search and **ChatTokener brings it back**, with all the context, in compressed but complete form. ğŸ§ âœ¨

---

## ğŸš§ **Project Status**

**ChatTokener Suite is currently under active development.**

If you want early access to the complete suite, you can join the **joining list** by simply sending an email to the address provided with the subject "**ChatTokener**".

---

**Author**: Russo Davide (The DaveEloper)  
**Email**: vibecoding@pcok.it  
**Project**: ChatTokener Suite  
**Component**: Manual Overview Documentation